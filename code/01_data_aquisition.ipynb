{
 "cells": [
  {
   "cell_type": "raw",
   "id": "43505ab2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "144216ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "from zipfile import ZipFile\n",
    "import ftplib \n",
    "import cdsapi\n",
    "import yaml\n",
    "import xarray as xr\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1268cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file contains configuration details like API keys and passwords\n",
    "global_vars = yaml.safe_load(open('../config.yml', 'r') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1facbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This has custom functions - specifically the \"download\" function \n",
    "%run ./00_custom_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec389132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/artemis/workspace/ds4114/online_data/\n"
     ]
    }
   ],
   "source": [
    "#Data will be saved at this location in folders such as root/SST/originals/ and root/SSS/orginals/\n",
    "#Note that these folder locations must already be created as a manual validation step\n",
    "download_folder_root = global_vars['download_folder']\n",
    "print(download_folder_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f639250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following two variables are used to acquire select data when it is uploaded by month or year.\n",
    "    #Data that is not uploaded by year includes: SST (NOAA); MLD (deBoyer & Argo), fCO2 (SOCAT), xCO2, Coastal, SeaFlux\n",
    "#These set the start and end years (inclusive) and do not need to be changed.\n",
    "#Some years/months of data may not available (because prior to when data was gathered or too recent for the source).\n",
    "    #In those cases any available data is obtained in this range. Specifically, \n",
    "        #SST (NOAA) data only 1981-present\n",
    "        #SST (ERA5) data only 1979-present\n",
    "        #SST (JRA55) data only 1958-2023\n",
    "        #SSS data only 1900-present\n",
    "        #MLD (deBoyer and Argo) data only an averaged 12 months\n",
    "        #CHL data only 1997-present\n",
    "        #fCO2 data only 1970-2022\n",
    "        #SLP data only 1979-2022\n",
    "        #xCO2 data only 1979-present\n",
    "        #Coastal data only an averaged 12 months \n",
    "        #SeaFlux data only 1982-2022\n",
    "    #These limitations are hardcoded so other sources or links would be needed to download outside of this range \n",
    "acquisition_start_year = 1979 \n",
    "acquisition_end_year = 2023  \n",
    "\n",
    "#This variable sets the output filetype for SSS and CHL data and needs to specified explicitly because of the unique way the are downloaded.\n",
    "#By default, all data source downloads will default to the netcdf format unless using cloud storage. \n",
    "#When using cloud storage, it is recommended to use ARCO (Analysis-Ready Cloud-Optimized) formats like Zarr over NetCDF\n",
    "output_file_type = '.zarr' if download_folder_root[0:5] == 'gs://' else '.nc'\n",
    "\n",
    "#This variable is used for naming files (SST & xCO2)\n",
    "today_yearmonth = datetime.datetime.now().strftime('%Y%m')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5389364c-77b5-43a2-a6ef-eea481432feb",
   "metadata": {},
   "source": [
    "#just for debugging\n",
    "acquisition_start_year = 2000\n",
    "acquisition_end_year = 2000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f22f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key already installed\n"
     ]
    }
   ],
   "source": [
    "#Some data (SLP, SST) requires an account on European Centre for Medium-Range Weather Forecasts and an API key\n",
    "#More info can be found https://cds.climate.copernicus.eu/api-how-to\n",
    "#Once the packages is installed (conda install -c conda-forge cdsapi), we need to install your API key using code below\n",
    "\n",
    "cds_url= \"url: https://cds.climate.copernicus.eu/api/v2\"\n",
    "cds_key= 'key: '+global_vars['cds_api_key']  #from the configuration file\n",
    "file = os.path.expanduser('~')+'/.cdsapirc'\n",
    "if not (os.path.isfile(file)): \n",
    "    cds_file = open(file, \"w\")\n",
    "    cds_file.write(cds_url+'\\n')\n",
    "    cds_file.write(cds_key)\n",
    "    cds_file.close()\n",
    "else:\n",
    "    print(\"API key already installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd978d",
   "metadata": {},
   "source": [
    "## Temperature (SST)\n",
    "#### NOAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ef2e9-fbe1-4c6a-b08d-ec7b7e841dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOAA SST is easy because NOAA uses the same URL for all data across time periods (1981-09 to present only)\n",
    "#More info found on https://psl.noaa.gov/data/gridded/data.noaa.oisst.v2.highres.html\n",
    "sst_direct_url = 'https://downloads.psl.noaa.gov/Datasets/noaa.oisst.v2.highres/sst.mon.mean.nc' \n",
    "sst_destination_folder = download_folder_root+r'SST/originals/'\n",
    "sst_destination_filename = 'SST_NOAA_OI-V2-HighRes_198109-'+today_yearmonth+'.nc'  #data is only from 1981\n",
    "download(sst_direct_url, sst_destination_folder, sst_destination_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e59b7b-999b-4e45-8302-5970f580f36a",
   "metadata": {},
   "source": [
    "#### ECMWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53cad2ab-8657-4391-a7a6-fc9148bffb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File SST_ECMWF_ERA5-monthly-reanalysis-SST_1999.nc already exists - (skipping download from 1999 )\n",
      "File SST_ECMWF_ERA5-monthly-reanalysis-SST_2000.nc already exists - (skipping download from 2000 )\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#This SST dataset comes from European Centre for Medium-Range Weather Forecasts (1979-01 to present only). It is the same as the one used for SLP below.\n",
    "#More info can be found on https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels-monthly-means?tab=form\n",
    "#We installed the API and have an account, so now we can download the ERA5 data via a loop (yearly)\n",
    "#While this data can be downloaded together with SLP, we have chosen to break up the downloads for clarity and organization\n",
    "sst_destination_folder = download_folder_root+r'SST/originals/'\n",
    "for year in range(acquisition_start_year, acquisition_end_year+1, 1):\n",
    "    sst_destination_filename = ''\n",
    "    months = []\n",
    "    if year == datetime.datetime.now().year:   #if a partial year; this prevents erorrs trying to use the API to get future/non-existant data    \n",
    "        months = [i for i in range(1,datetime.datetime.now().month -1)]  \n",
    "        sst_destination_filename = 'SST_ECMWF_ERA5-monthly-reanalysis-SST_'+str(year)+'-partial.nc'  \n",
    "        #Note, partial years will not automatically be overwritten so you must manually clean up unneeded files\n",
    "    else:\n",
    "        sst_destination_filename = 'SST_ECMWF_ERA5-monthly-reanalysis-SST_'+str(year)+'.nc'\n",
    "        months = [i for i in range(1,12+1)]\n",
    "\n",
    "    cdsapi_custom_download(year, months, 'sea_surface_temperature', sst_destination_folder, sst_destination_filename, overwrite=False, create_dest=False)\n",
    "    \n",
    "print(\"ERA5 SST Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9765fdc-cc85-40c6-97ee-ce594a2a6283",
   "metadata": {},
   "source": [
    "#### JRA55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91d6e0e7-8184-4f43-a2a8-0b5449550a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File SST_JMA_JRA55-do-daily-reanalysis-SST_1999.nc already exists - (skipping download from https://esgf-data2.llnl.gov/thredds/fileServer/user_pub_work/input4MIPs/CMIP6/OMIP/MRI/MRI-JRA55-do-1-5-0/ocean/day/tos/gn/v20200916/tos_input4MIPs_atmosphericState_OMIP_MRI-JRA55-do-1-5-0_gn_19990101-19991231.nc )\n",
      "File SST_JMA_JRA55-do-daily-reanalysis-SST_2000.nc already exists - (skipping download from https://esgf-data2.llnl.gov/thredds/fileServer/user_pub_work/input4MIPs/CMIP6/OMIP/MRI/MRI-JRA55-do-1-5-0/ocean/day/tos/gn/v20200916/tos_input4MIPs_atmosphericState_OMIP_MRI-JRA55-do-1-5-0_gn_20000101-20001231.nc )\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#This SST data source comes from Japan Meteorological Agency (JMA) (195801 - to 2023 only)\n",
    "#JRA55-do (Tsujino et al., 2018)  corrects the atmospheric reanalysis product JRA-55 (Kobayashi et al., 2015) \n",
    "#More info can be found on https://climate.mri-jma.go.jp/pub/ocean/JRA55-do/\n",
    "\n",
    "sst_destination_folder = download_folder_root+r'SST/originals/'\n",
    "for year in range(acquisition_start_year, acquisition_end_year+1, 1):\n",
    "    sst_jra55_destination_filename = 'SST_JMA_JRA55-do-daily-reanalysis-SST_'+str(year)+'.nc'\n",
    "    direct_link = None\n",
    "    \n",
    "    #downloading via direct links. Recent data (2020+) is hosted on a different site\n",
    "    if year == 2020:\n",
    "        direct_link = 'https://climate.mri-jma.go.jp/pub/ocean/JRA55-do/ocean/day/tos/gn/v20210315/tos_input4MIPs_atmosphericState_OMIP_MRI-JRA55-do-1-5-0-1_gn_20200101-20201231.nc'\n",
    "    elif year == 2021:\n",
    "        direct_link = 'https://climate.mri-jma.go.jp/pub/ocean/JRA55-do/ocean/day/tos/gn/latest/tos_input4MIPs_atmosphericState_OMIP_MRI-JRA55-do-1-5-0-1_gn_20210101-20211231.nc'\n",
    "    elif year == 2022:\n",
    "        direct_link = 'https://climate.mri-jma.go.jp/pub/ocean/JRA55-do/ocean/day/tos/gn/latest/tos_input4MIPs_atmosphericState_OMIP_MRI-JRA55-do-1-5-0-1_gn_20220101-20221231.nc'\n",
    "    elif year == 2023:\n",
    "        direct_link = 'https://climate.mri-jma.go.jp/pub/ocean/JRA55-do/ocean/day/tos/gn/latest/tos_input4MIPs_atmosphericState_OMIP_MRI-JRA55-do-1-5-0-1_gn_20230101-20230629.nc'\n",
    "        sst_jra55_destination_filename = 'SST_JMA_JRA55-do-daily-reanalysis-SST_'+str(year)+'-partial.nc' #because only part of the year available\n",
    "    else:\n",
    "        base = 'https://esgf-data2.llnl.gov/thredds/fileServer/user_pub_work/input4MIPs/CMIP6/OMIP/MRI/MRI-JRA55-do-1-5-0/ocean/day/tos/gn/v20200916/tos_input4MIPs_atmosphericState_OMIP_MRI-JRA55-do-1-5-0_gn_'\n",
    "        end = str(year)+'0101-'+str(year)+'1231.nc'\n",
    "        direct_link = base + end  #ex: #https://esgf-data2.llnl.gov/thredds/fileServer/user_pub_work/input4MIPs/CMIP6/OMIP/MRI/MRI-JRA55-do-1-5-0/ocean/day/tos/gn/v20200916/tos_input4MIPs_atmosphericState_OMIP_MRI-JRA55-do-1-5-0_gn_19580101-19581231.nc\n",
    "    \n",
    "    download(direct_link, sst_destination_folder, sst_jra55_destination_filename)\n",
    "print(\"JRA55 SST Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be58d7a",
   "metadata": {},
   "source": [
    "## Salinity (SSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99b1ccc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File SSS_Met-Office-Hadley-Centre_EN422f-g10-analyses_2000.zip already exists - (skipping download from https://www.metoffice.gov.uk/hadobs/en4/data/en4-2-1/EN.4.2.2/EN.4.2.2.analyses.g10.2000.zip )\n",
      "Cancelling output - EN.4.2.2.f.analysis.g10.200001.nc already exists in /data/artemis/workspace/ds4114/online_data/SSS/originals/\n",
      "Cancelling output - EN.4.2.2.f.analysis.g10.200002.nc already exists in /data/artemis/workspace/ds4114/online_data/SSS/originals/\n",
      "Cancelling output - EN.4.2.2.f.analysis.g10.200003.nc already exists in /data/artemis/workspace/ds4114/online_data/SSS/originals/\n",
      "Cancelling output - EN.4.2.2.f.analysis.g10.200004.nc already exists in /data/artemis/workspace/ds4114/online_data/SSS/originals/\n",
      "Cancelling output - EN.4.2.2.f.analysis.g10.200005.nc already exists in /data/artemis/workspace/ds4114/online_data/SSS/originals/\n",
      "Cancelling output - EN.4.2.2.f.analysis.g10.200006.nc already exists in /data/artemis/workspace/ds4114/online_data/SSS/originals/\n",
      "Cancelling output - EN.4.2.2.f.analysis.g10.200007.nc already exists in /data/artemis/workspace/ds4114/online_data/SSS/originals/\n",
      "Cancelling output - EN.4.2.2.f.analysis.g10.200008.nc already exists in /data/artemis/workspace/ds4114/online_data/SSS/originals/\n",
      "Cancelling output - EN.4.2.2.f.analysis.g10.200009.nc already exists in /data/artemis/workspace/ds4114/online_data/SSS/originals/\n",
      "Cancelling output - EN.4.2.2.f.analysis.g10.200010.nc already exists in /data/artemis/workspace/ds4114/online_data/SSS/originals/\n",
      "Cancelling output - EN.4.2.2.f.analysis.g10.200011.nc already exists in /data/artemis/workspace/ds4114/online_data/SSS/originals/\n",
      "Cancelling output - EN.4.2.2.f.analysis.g10.200012.nc already exists in /data/artemis/workspace/ds4114/online_data/SSS/originals/\n"
     ]
    }
   ],
   "source": [
    "#SST requires downloading yearly zip files and extracting each month from each  (1900-01 to present only)\n",
    "#More info found on https://www.metoffice.gov.uk/hadobs/en4/download-en4-2-2.html\n",
    "\n",
    "sss_direct_url_base = 'https://www.metoffice.gov.uk/hadobs/en4/data/en4-2-1/EN.4.2.2/'\n",
    "sss_destination_filename_base = 'SSS_Met-Office-Hadley-Centre_EN422f-g10-analyses_' #_197901+\n",
    "sss_destination_folder = download_folder_root+r'SSS/originals/'\n",
    "for year in range(acquisition_start_year, acquisition_end_year+1, 1):\n",
    "    if year >= 2021: sss_direct_url_base = 'https://www.metoffice.gov.uk/hadobs/en4/data/en4-2-1/' #2021 and onward the URL changes, though both URL zips exists. Not clear why.\n",
    "    url_file = 'EN.4.2.2.analyses.g10.'+str(year)+'.zip'\n",
    "    sss_direct_url = sss_direct_url_base + url_file\n",
    "    sss_destination_filename = sss_destination_filename_base+str(year)+'.zip'\n",
    "    \n",
    "    #download to tmp, extract a year, then transfer all to destination\n",
    "    tmp_folder = '../tmp/'\n",
    "    download_to_folder(sss_direct_url, tmp_folder, sss_destination_filename,overwrite=False, create_dest=True)\n",
    "    ZipFile(tmp_folder+sss_destination_filename).extractall(tmp_folder)\n",
    "    files = glob.glob(tmp_folder+'EN.4.2.2.f.analysis.g10.*.nc')\n",
    "    for f in files:  #for each file extracted\n",
    "        basename = os.path.basename(f)\n",
    "        tmp_xr = xr.open_dataset(tmp_folder + basename)\n",
    "        output_xarray_with_date(tmp_xr, sss_destination_folder, basename, filetype=output_file_type, with_date=False) \n",
    "            #Note the filename is kept as the original from the .zip here to be compatible with other work. To output the file with a different name, edit the dest_file string parameter.\n",
    "        os.remove(os.path.join(tmp_folder,f)) #remove tmp file\n",
    "    \n",
    "    #remove zip file too\n",
    "    os.remove(os.path.join(tmp_folder,sss_destination_filename)) #remove tmp file\n",
    "print(\"SSS Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bcf54f",
   "metadata": {},
   "source": [
    "## Mixed Layer Depth (MLD)\n",
    "#### deBoyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46a2ad35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File MLD_IFREMER-deBoyer_DT02-c1m_2008.nc already exists - (skipping download from https://cerweb.ifremer.fr/deboyer/data/mld_DT02_c1m_reg2.0.nc )\n"
     ]
    }
   ],
   "source": [
    "#MLD data is just one year of data that was processed by the author using several years of temperature profiles (data from 1941-2008, partially missing)\n",
    "#More info found on https://cerweb.ifremer.fr/deboyer/mld/Surface_Mixed_Layer_Depth.php\n",
    "\n",
    "mld_direct_url = 'https://cerweb.ifremer.fr/deboyer/data/mld_DT02_c1m_reg2.0.nc'\n",
    "mld_destination_folder = download_folder_root+r'MLD/originals/'\n",
    "mld_destination_filename = 'MLD_IFREMER-deBoyer_DT02-c1m_2008.nc'   #2008 though data is blended across years \n",
    "download(mld_direct_url, mld_destination_folder, mld_destination_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338922f-0328-486a-926f-4425ea8620dd",
   "metadata": {},
   "source": [
    "#### Argo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "037e9443-d88c-4cae-8e77-bdaa9d06e9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving http://mixedlayer.ucsd.edu/data/Argo_mixedlayers_monthlyclim_04142022.nc to /data/artemis/workspace/ds4114/online_data/MLD/originals/MLD_UCSD-Argo_mixedlayers-monthlyclim_2022.nc...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# This MLD source is from UC San Diego who used Argo data to create the climatology\n",
    "# More info can be found on http://mixedlayer.ucsd.edu/ and https://www.seanoe.org/data/00311/42182/#56126\n",
    "mld_direct_url = 'http://mixedlayer.ucsd.edu/data/Argo_mixedlayers_monthlyclim_04142022.nc'\n",
    "mld_destination_folder = download_folder_root+r'MLD/originals/'\n",
    "mld_destination_filename = 'MLD_UCSD-Argo_mixedlayers-monthlyclim_2022.nc'   #2022 though data is blended across years \n",
    "download(mld_direct_url, mld_destination_folder, mld_destination_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f6989",
   "metadata": {},
   "source": [
    "## Chlorophyll (CHL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce878bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'230 User ftp_gc_VBennington logged in'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHL data needs to be downloaded via FTP in monthly files (1997-09 to present only)\n",
    "#According to https://www.globcolour.info/products_description_mermet.html, we want to use GSM data only\n",
    "#Note that the product changes over the years and the file names can vary. However there is a common pattern in naming used below.\n",
    "#More info found on https://hermes.acri.fr/index.php?class=archive\n",
    "\n",
    "#FTP requires an account and login:\n",
    "chl_direct_ftp = 'ftp.hermes.acri.fr'\n",
    "chl_destination_folder = download_folder_root+r'CHL/originals/'\n",
    "chl_acquisition_start_year = acquisition_start_year if acquisition_start_year >= 1997 else 1997 #earliest we have is 1997-09 so set it here to prevent errors getting nonexistant data\n",
    "usr = global_vars['chl_user'] \n",
    "psw = global_vars['chl_psw'] \n",
    "\n",
    "ftp_server = ftplib.FTP(chl_direct_ftp)\n",
    "ftp_server.set_pasv(True)\n",
    "ftp_server.login(usr, psw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1b72026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxrwxr-x   3 10048    45005           0 Aug 20  2021 animation\n",
      "drwxrwsr-x  11 10048    45005           0 Apr 13 13:57 ATLNW\n",
      "drwxrwsr-x  12 10048    45005           0 Sep 30  2022 EURO\n",
      "drwxrwsr-x  13 10048    45005           3 Jan 30  2023 GLOB\n",
      "drwxrwsr-x   5 10048    45005           0 Mar 27  2021 GLOBCOAST\n",
      "drwxrwxr-x   5 10048    45005           0 Dec  2  2014 OSS2015\n"
     ]
    }
   ],
   "source": [
    "#Note the nlst command used below may throw a [WinError 10060] message after logging in. This may be due to how the FTP server is configured or how the local computer is configured. \n",
    "#If the following command does not work, there is a broader issue with the connection.\n",
    "ftp_server.dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0169e4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading L3m_20000101-20000131__GLOB_100_GSM-SWF_CHL1_MO_00.nc as CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200001.nc\n",
      "Cancelling output - CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200001.nc already exists in /data/artemis/workspace/ds4114/online_data/CHL/originals/\n",
      "Downloading L3m_20000201-20000229__GLOB_100_GSM-SWF_CHL1_MO_00.nc as CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200002.nc\n",
      "Cancelling output - CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200002.nc already exists in /data/artemis/workspace/ds4114/online_data/CHL/originals/\n",
      "Downloading L3m_20000301-20000331__GLOB_100_GSM-SWF_CHL1_MO_00.nc as CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200003.nc\n",
      "Cancelling output - CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200003.nc already exists in /data/artemis/workspace/ds4114/online_data/CHL/originals/\n",
      "Downloading L3m_20000401-20000430__GLOB_100_GSM-SWF_CHL1_MO_00.nc as CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200004.nc\n",
      "Cancelling output - CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200004.nc already exists in /data/artemis/workspace/ds4114/online_data/CHL/originals/\n",
      "Downloading L3m_20000501-20000531__GLOB_100_GSM-SWF_CHL1_MO_00.nc as CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200005.nc\n",
      "Cancelling output - CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200005.nc already exists in /data/artemis/workspace/ds4114/online_data/CHL/originals/\n",
      "Downloading L3m_20000601-20000630__GLOB_100_GSM-SWF_CHL1_MO_00.nc as CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200006.nc\n",
      "Cancelling output - CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200006.nc already exists in /data/artemis/workspace/ds4114/online_data/CHL/originals/\n",
      "Downloading L3m_20000701-20000731__GLOB_100_GSM-SWF_CHL1_MO_00.nc as CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200007.nc\n",
      "Cancelling output - CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200007.nc already exists in /data/artemis/workspace/ds4114/online_data/CHL/originals/\n",
      "Downloading L3m_20000801-20000831__GLOB_100_GSM-SWF_CHL1_MO_00.nc as CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200008.nc\n",
      "Cancelling output - CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200008.nc already exists in /data/artemis/workspace/ds4114/online_data/CHL/originals/\n",
      "Downloading L3m_20000901-20000930__GLOB_100_GSM-SWF_CHL1_MO_00.nc as CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200009.nc\n",
      "Cancelling output - CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200009.nc already exists in /data/artemis/workspace/ds4114/online_data/CHL/originals/\n",
      "Downloading L3m_20001001-20001031__GLOB_100_GSM-SWF_CHL1_MO_00.nc as CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200010.nc\n",
      "Cancelling output - CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200010.nc already exists in /data/artemis/workspace/ds4114/online_data/CHL/originals/\n",
      "Downloading L3m_20001101-20001130__GLOB_100_GSM-SWF_CHL1_MO_00.nc as CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200011.nc\n",
      "Cancelling output - CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200011.nc already exists in /data/artemis/workspace/ds4114/online_data/CHL/originals/\n",
      "Downloading L3m_20001201-20001231__GLOB_100_GSM-SWF_CHL1_MO_00.nc as CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200012.nc\n",
      "Cancelling output - CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_200012.nc already exists in /data/artemis/workspace/ds4114/online_data/CHL/originals/\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "for year in range(chl_acquisition_start_year, acquisition_end_year+1, 1):\n",
    "    chl_destination_filename = ''\n",
    "    months = [i for i in range(1,12+1)]\n",
    "     #if a partial year, reduce available months\n",
    "    if year == datetime.datetime.now().year: months = [i for i in range(1,datetime.datetime.now().month)]\n",
    "    elif year == 1997: months = [i for i in range(9,12+1)] #data only available part of 1997\n",
    "    for month in months:\n",
    "        chl_destination_filename = 'CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_'+str(year)+str(month).zfill(2)+'.nc'\n",
    "        ftp_server.cwd(f'/GLOB/merged/month/{year}/{str(month).zfill(2)}/01') #ex. '/GLOB/merged/month/2022/02/01' for Feb 2022\n",
    "        f = ftp_server.nlst('L3m*GLOB*100*GSM*CHL1*.nc')[0]    #Global view, 100 km resolution, GSM product, CHL1 data\n",
    "        \n",
    "        #download to tmp folder first, then check and transfer to destination\n",
    "        tmp_folder = '../tmp/'\n",
    "        if not os.path.exists(tmp_folder): os.makedirs(tmp_folder)\n",
    "        print(f'Downloading {f} as {chl_destination_filename}')\n",
    "        ftp_server.retrbinary(\"RETR \" + f, open(tmp_folder + chl_destination_filename, 'wb').write)\n",
    "        tmp_xr = xr.open_dataset(tmp_folder + chl_destination_filename)\n",
    "        output_xarray_with_date(tmp_xr, chl_destination_folder, chl_destination_filename, filetype=output_file_type, with_date=False)\n",
    "        del tmp_xr\n",
    "        os.remove(os.path.join(tmp_folder , chl_destination_filename)) #remove tmp file\n",
    "            \n",
    "print(\"CHL Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e28ac94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'221 Goodbye.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftp_server.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611b650",
   "metadata": {},
   "source": [
    "## pCO2 \n",
    "### SOCAT fCO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ac3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pCO2 data is calculated from fCO2 and SST (SOCOVV) and sea level pressure (ECMRWF) so we need to obtain a dataset for both\n",
    "\n",
    "#fCO2 and SST comes from the Surface Ocean CO2 Variability and Vulnerability group (1970-01 to end of last year only)\n",
    "#We want to use the same SST data points related to fCO2 from the same source (not using the separate NOAA SST here).\n",
    "#More info can be found at https://www.socat.info/index.php/data-access/\n",
    "fco2_direct_url = 'https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0278913/SOCATv2023_Gridded_Dat/SOCATv2023_tracks_gridded_monthly.nc'  #thru 2022-12\n",
    "      #previously 'https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0253659/SOCATv2022_Gridded_Dat/SOCATv2022_tracks_gridded_monthly.nc'  #thru 2021-12\n",
    "fco2_destination_folder = download_folder_root+r'pCO2/originals/'    \n",
    "fco2_destination_filename = 'fCO2_SOCOVV_SOCAT-gridded-monthly_2022.nc'    #filename year changed from source to denote data date, not publish date\n",
    "download(fco2_direct_url, fco2_destination_folder, fco2_destination_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9fb6c2-8b65-4a62-b5c8-fa359753687c",
   "metadata": {},
   "source": [
    "### Coastal Filling (pCO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82aa8328-08aa-4b02-9bcb-f2880c40be4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0209633/MPI-ULB-SOM_FFN_clim.nc to /data/artemis/workspace/ds4114/online_data/pCO2/originals/pCO2_NOAA-NCEI_MPI-ULB-SOM-FFN_1988-2020.nc...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#This data set is used for enhancing coastal areas for flux calculation\n",
    "#More info can be found https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.nodc:0209633 and https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0209633/\n",
    "coastal_clim_direct = 'https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0209633/MPI-ULB-SOM_FFN_clim.nc'\n",
    "coastal_clim_destination_folder = download_folder_root+r'pCO2/originals/' \n",
    "coastal_clim_filename = 'pCO2_NOAA-NCEI_MPI-ULB-SOM-FFN_1988-2020.nc'\n",
    "download(coastal_clim_direct, coastal_clim_destination_folder, coastal_clim_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f64b0d-d568-4def-8a6a-e2814816b195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b70a1990",
   "metadata": {},
   "source": [
    "## Sea Level Pressure (SLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddc4ffc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File SLP_ECMWF_ERA5-monthly-reanalysis-MSLP_1999.nc already exists - (skipping download from 1999 )\n",
      "File SLP_ECMWF_ERA5-monthly-reanalysis-MSLP_2000.nc already exists - (skipping download from 2000 )\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#Sea level pressure comes from European Centre for Medium-Range Weather Forecasts (1979-01 to present only). It is the same source the one used for one SST above.\n",
    "#More info can be found on https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels-monthly-means?tab=form\n",
    "#We installed the API and have an account, so now we can download the ERA5 data via a loop (yearly)\n",
    "slp_destination_folder = download_folder_root+r'SLP/originals/'    \n",
    "for year in range(acquisition_start_year, acquisition_end_year+1, 1):\n",
    "    slp_destination_filename = ''\n",
    "    months = []\n",
    "    if year == datetime.datetime.now().year:   #if a partial year; this prevents erorrs trying to use the API to get future/non-existant data    \n",
    "        months = [i for i in range(1,datetime.datetime.now().month)]  \n",
    "        slp_destination_filename = 'SLP_ECMWF_ERA5-monthly-reanalysis-MSLP_'+str(year)+'-partial.nc'  \n",
    "        #To consider, do we want to automatically overwrite parital years?\n",
    "    else:\n",
    "        slp_destination_filename = 'SLP_ECMWF_ERA5-monthly-reanalysis-MSLP_'+str(year)+'.nc'\n",
    "        months = [i for i in range(1,12+1)]\n",
    "\n",
    "    cdsapi_custom_download(year, months, 'mean_sea_level_pressure', slp_destination_folder, slp_destination_filename, overwrite=False, create_dest=False)\n",
    "    \n",
    "print(\"SLP Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21631a30",
   "metadata": {},
   "source": [
    "## Atmospheric CO2 (xCO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf92775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xCO2 comes from NOAA. More information: https://gml.noaa.gov/ccgg/trends/gl_data.html\n",
    "\n",
    "xco2_direct_url = \"https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_gl.csv\"\n",
    "xco2_destination_folder = download_folder_root+r'xCO2/originals'\n",
    "today_yearmonth = datetime.datetime.now().strftime('%Y%m')\n",
    "xco2_destination_filename = 'xCO2_NOAA_xCO2-mm-gl-monthly_197901-'+today_yearmonth+'.csv'\n",
    "download(xco2_direct_url, xco2_destination_folder, xco2_destination_filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f7706",
   "metadata": {},
   "source": [
    "## SeaFlux\n",
    "#### All (Wind, Ice, Ocean Area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcfb0664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File SeaFlux_LDEO_SeaFlux-v202301-all_1982-2022.nc already exists - (skipping download from https://zenodo.org/record/8099928/files/SeaFlux.v2023.01_all_1982-2022.nc )\n"
     ]
    }
   ],
   "source": [
    "#This data is is not required for pCO2 reconstruction but is used for calculating flux\n",
    "#LDEO product is updated through the end of the previous year\n",
    "#More information can be found https://zenodo.org/record/8099928\n",
    "\n",
    "seaflux_all_direct = 'https://zenodo.org/record/8099928/files/SeaFlux.v2023.01_all_1982-2022.nc'\n",
    "seaflux_destination_folder = download_folder_root+r'SeaFlux/originals/'\n",
    "seaflux_destination_filename = 'SeaFlux_LDEO_SeaFlux-v202301-all_1982-2022.nc'\n",
    "download(seaflux_all_direct, seaflux_destination_folder, seaflux_destination_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b67ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023a8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leap_test202308-2",
   "language": "python",
   "name": "leap_test202308-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
