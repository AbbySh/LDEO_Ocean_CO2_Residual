{
 "cells": [
  {
   "cell_type": "raw",
   "id": "43505ab2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144216ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "from zipfile import ZipFile\n",
    "import ftplib \n",
    "import cdsapi\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1268cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file contains configuration details like API keys and passwords\n",
    "global_vars = yaml.safe_load(open('../config.yml', 'r') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1facbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This has custom functions - specifically the \"download\" function \n",
    "%run ./00_custom_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec389132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data will be saved at this location in folders such as root/SST/originals/ and root/SSS/orginals/\n",
    "cloud = False\n",
    "if cloud:\n",
    "    download_folder_root = global_vars['download_folder_cloud']\n",
    "else:\n",
    "    download_folder_root = global_vars['download_folder_local']\n",
    "print(download_folder_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f639250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following two variables are used to acquire select data when it is uploaded by month or year. \n",
    "#These set the start and end years (inclusive) and do not need to be changed.\n",
    "#Some years/months of data may not available (because prior to when data was gathered or too recent for the source).\n",
    "    #In those cases any available data is obtained in this range. Specifically, \n",
    "        #SST data only 1981-present\n",
    "        #SSS data only 1900-present\n",
    "        #MLD data only an averaged 12 months\n",
    "        #CHL data only 1997-present\n",
    "        #fCO2 data only 1970-2022\n",
    "        #SLP data only 1979-2022\n",
    "        #xCO2 data only 1979-present\n",
    "        #SeaFlux data only 1982-2022\n",
    "    #These limitations are hardcoded so other sources or links would be needed to download outside of this range \n",
    "acquisition_start_year = 1979 \n",
    "acquisition_end_year = 2023  \n",
    "\n",
    "#This variable is used for naming files (SST & xCO2)\n",
    "today_yearmonth = datetime.datetime.now().strftime('%Y%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd978d",
   "metadata": {},
   "source": [
    "## Temperature (SST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8418f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SST is easy because NOAA uses the same URL for all data across time periods (1981-09 to present only)\n",
    "#More info found on https://psl.noaa.gov/data/gridded/data.noaa.oisst.v2.highres.html\n",
    "sst_direct_url = 'https://downloads.psl.noaa.gov/Datasets/noaa.oisst.v2.highres/sst.mon.mean.nc' \n",
    "sst_destination_folder = download_folder_root+r'SST/originals/'\n",
    "sst_destination_filename = 'SST_NOAA_OI-V2-HighRes_198109-'+today_yearmonth+'.nc'  #data is only from 1981\n",
    "download(sst_direct_url, sst_destination_folder, sst_destination_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be58d7a",
   "metadata": {},
   "source": [
    "## Salinity (SSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SST requires downloading yearly zip files and extracting each month from each  (1900-01 to present only)\n",
    "#More info found on https://www.metoffice.gov.uk/hadobs/en4/download-en4-2-2.html\n",
    "\n",
    "sss_direct_url_base = 'https://www.metoffice.gov.uk/hadobs/en4/data/en4-2-1/EN.4.2.2/'\n",
    "sss_destination_filename_base = 'SSS_Met-Office-Hadley-Centre_EN422f-g10-analyses_' #_197901+\n",
    "sss_destination_folder = download_folder_root+r'SSS/originals/'\n",
    "for year in range(acquisition_start_year, acquisition_end_year+1, 1):\n",
    "    if year >= 2021: sss_direct_url_base = 'https://www.metoffice.gov.uk/hadobs/en4/data/en4-2-1/' #2021 and onward the URL changes, though both URL zips exists. Not clear why.\n",
    "    url_file = 'EN.4.2.2.analyses.g10.'+str(year)+'.zip'\n",
    "    sss_direct_url = sss_direct_url_base + url_file\n",
    "    sss_destination_filename = sss_destination_filename_base+str(year)+'.zip'\n",
    "    download(sss_direct_url, sss_destination_folder, sss_destination_filename)\n",
    "    #next, unzip the download. Note this will overwrite files that may have been previously extracted so may need to wrap in an if statement\n",
    "    ZipFile(sss_destination_folder+sss_destination_filename).extractall(sss_destination_folder) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bcf54f",
   "metadata": {},
   "source": [
    "## Mixed Layer Depth (MLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a2ad35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MLD data is just one year of data that was processed by the author using several years of temperature profiles (data from 1941-2008, partially missing)\n",
    "#More info found on https://cerweb.ifremer.fr/deboyer/mld/Surface_Mixed_Layer_Depth.php\n",
    "\n",
    "mld_direct_url = 'https://cerweb.ifremer.fr/deboyer/data/mld_DT02_c1m_reg2.0.nc'\n",
    "mld_destination_folder = download_folder_root+r'MLD/originals/'\n",
    "mld_destination_filename = 'MLD_IFREMER-deBoyer_DT02-c1m_2008.nc'   #2008 though data is blended across years \n",
    "download(mld_direct_url, mld_destination_folder, mld_destination_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f6989",
   "metadata": {},
   "source": [
    "## Chlorophyll (CHL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce878bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHL data needs to be downloaded via FTP in monthly files (1997-09 to present only)\n",
    "#According to https://www.globcolour.info/products_description_mermet.html, we want to use GSM data only\n",
    "#Note that the product changes over the years and the file names can vary. However there is a common pattern in naming used below.\n",
    "#More info found on https://hermes.acri.fr/index.php?class=archive\n",
    "\n",
    "#FTP requires an account and login:\n",
    "chl_direct_ftp = 'ftp.hermes.acri.fr'\n",
    "chl_destination_folder = download_folder_root+r'CHL/originals/'\n",
    "chl_acquisition_start_year = acquisition_start_year if acquisition_start_year >= 1997 else 1997 #earliest we have is 1997-09 so set it here to prevent errors getting nonexistant data\n",
    "usr = global_vars['chl_user'] \n",
    "psw = global_vars['chl_psw'] \n",
    "\n",
    "ftp_server = ftplib.FTP(chl_direct_ftp)\n",
    "ftp_server.set_pasv(True)\n",
    "ftp_server.login(usr, psw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b72026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note the nlst command used below may throw a [WinError 10060] message after logging in. This may be due to how the FTP server is configured or how the local computer is configured. \n",
    "#If the following command does not work, there is a broader issue with the connection.\n",
    "ftp_server.dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0169e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(chl_acquisition_start_year, acquisition_end_year+1, 1):\n",
    "    chl_destination_filename = ''\n",
    "    months = [i for i in range(1,12+1)]\n",
    "     #if a partial year, reduce available months\n",
    "    if year == datetime.datetime.now().year: months = [i for i in range(1,datetime.datetime.now().month)]\n",
    "    elif year == 1997: months = [i for i in range(9,12+1)] #data only available part of 1997\n",
    "    for month in months:\n",
    "        chl_destination_filename = 'CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_'+str(year)+str(month).zfill(2)+'.nc'\n",
    "        ftp_server.cwd(f'/GLOB/merged/month/{year}/{str(month).zfill(2)}/01') #ex. '/GLOB/merged/month/2022/02/01' for Feb 2022\n",
    "        f = ftp_server.nlst('L3m*GLOB*100*GSM*CHL1*.nc')[0]    #Global view, 100 km resolution, GSM product, CHL1 data\n",
    "        \n",
    "        if not (os.path.isfile(chl_destination_folder + chl_destination_filename)):  #if file does not exists \n",
    "            print(f'Downloading {f} as {chl_destination_filename}')\n",
    "            ftp_server.retrbinary(\"RETR \" + f, open(chl_destination_folder + chl_destination_filename, 'wb').write)\n",
    "        else:\n",
    "            print(f\"File already exists - (skipping download for {f} )\")\n",
    "            \n",
    "print(\"Complete\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ac94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp_server.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611b650",
   "metadata": {},
   "source": [
    "## pCO2 (fCO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ac3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pCO2 data is calculated from fCO2 and SST (SOCOVV) and sea level pressure (ECMRWF) so we need to obtain a dataset for both\n",
    "\n",
    "#fCO2 and SST comes from the Surface Ocean CO2 Variability and Vulnerability group (1970-01 to end of last year only)\n",
    "#We want to use the same SST data points related to fCO2 from the same source (not using the separate NOAA SST here).\n",
    "#More info can be found at https://www.socat.info/index.php/data-access/\n",
    "fco2_direct_url = 'https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0278913/SOCATv2023_Gridded_Dat/SOCATv2023_tracks_gridded_monthly.nc'  #thru 2022-12\n",
    "      #previously 'https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0253659/SOCATv2022_Gridded_Dat/SOCATv2022_tracks_gridded_monthly.nc'  #thru 2021-12\n",
    "fco2_destination_folder = download_folder_root+r'pCO2/originals/'    \n",
    "fco2_destination_filename = 'fCO2_SOCOVV_SOCAT-gridded-monthly_2022.nc'    #filename year changed from source to denote data date, not publish date\n",
    "download(fco2_direct_url, fco2_destination_folder, fco2_destination_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a1990",
   "metadata": {},
   "source": [
    "## Sea Level Pressure (SLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f22f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sea level pressure comes from European Centre for Medium-Range Weather Forecasts (1979-01 to present only)\n",
    "#requires an account and API key - once installed (conda install -c conda-forge cdsapi), need to create the API key using code below\n",
    "#More info can be found on https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels-monthly-means?tab=form\n",
    "cds_url= \"url: https://cds.climate.copernicus.eu/api/v2\"\n",
    "cds_key= 'key: '+global_vars['cds_api_key']\n",
    "file = os.path.expanduser('~')+'/.cdsapirc'\n",
    "if not (os.path.isfile(file)): \n",
    "    cds_file = open(file, \"w\")\n",
    "    cds_file.write(cds_url+'\\n')\n",
    "    cds_file.write(cds_key)\n",
    "    cds_file.close()\n",
    "else:\n",
    "    print(\"API key already installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have an account, we can download the ERA5 data via a loop (yearly)\n",
    "slp_destination_folder = download_folder_root+r'SLP/originals/'    \n",
    "for year in range(acquisition_start_year, acquisition_end_year+1, 1):\n",
    "    slp_destination_filename = ''\n",
    "    months = []\n",
    "    if year == datetime.datetime.now().year:   #if a partial year; this prevents erorrs trying to use the API to get future/non-existant data    \n",
    "        months = [i for i in range(1,datetime.datetime.now().month)]  \n",
    "        slp_destination_filename = 'SLP_ECMWF_ERA5-monthly-reanalysis-MSLP_'+str(year)+'-partial.nc'  \n",
    "        #To consider, do we want to automatically overwrite parital years?\n",
    "    else:\n",
    "        slp_destination_filename = 'SLP_ECMWF_ERA5-monthly-reanalysis-MSLP_'+str(year)+'.nc'\n",
    "        months = [i for i in range(1,12+1)]\n",
    "\n",
    "    if not os.path.isfile(slp_destination_folder + slp_destination_filename):  #if not already downloaded\n",
    "        c = cdsapi.Client()\n",
    "        c.retrieve(\n",
    "            'reanalysis-era5-single-levels-monthly-means',\n",
    "            {\n",
    "                'format': 'netcdf',\n",
    "                'year': year,\n",
    "                'variable': 'mean_sea_level_pressure',\n",
    "                'product_type': 'monthly_averaged_reanalysis',\n",
    "                'month': months,\n",
    "                'time': '00:00'\n",
    "            },\n",
    "            slp_destination_folder + slp_destination_filename)\n",
    "    else:\n",
    "        print(f\"File already exists - (skipping download for {year})\")\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21631a30",
   "metadata": {},
   "source": [
    "## Atmospheric CO2 (xCO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf92775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xCO2 comes from NOAA. More information: https://gml.noaa.gov/ccgg/trends/gl_data.html\n",
    "\n",
    "xco2_direct_url = \"https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_gl.csv\"\n",
    "xco2_destination_folder = download_folder_root+r'xCO2/originals'\n",
    "today_yearmonth = datetime.datetime.now().strftime('%Y%m')\n",
    "xco2_destination_filename = 'xCO2_NOAA_xCO2-mm-gl-monthly_197901-'+today_yearmonth+'.csv'\n",
    "download(xco2_direct_url, xco2_destination_folder, xco2_destination_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f7706",
   "metadata": {},
   "source": [
    "## SeaFlux\n",
    "#### All (Wind, Ice, Ocean Area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb0664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This data is is not required for pCO2 reconstruction but is used for calculating flux\n",
    "#LDEO product is updated through the end of the previous year\n",
    "#More information can be found https://zenodo.org/record/8099928\n",
    "\n",
    "seaflux_all_direct = 'https://zenodo.org/record/8099928/files/SeaFlux.v2023.01_all_1982-2022.nc?download=1'\n",
    "seaflux_destination_folder = download_folder_root+r'SeaFlux/originals/'\n",
    "seaflux_destination_filename = 'SeaFlux_LDEO_SeaFlux-v202301-all_1982-2022.nc'\n",
    "download(seaflux_all_direct, seaflux_destination_folder, seaflux_destination_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d703b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b67ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023a8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leap_co2_v1",
   "language": "python",
   "name": "leap_co2_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
