{
 "cells": [
  {
   "cell_type": "raw",
   "id": "98ee0a3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from numpy import errstate,isneginf,array\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean as cm    \n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file contains configuration details like API keys and passwords\n",
    "global_vars = yaml.safe_load(open('../config.yml', 'r') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e5d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This has custom functions - log transform\n",
    "%run ./00_custom_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72feffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set base folders\n",
    "cloud = False\n",
    "if cloud:\n",
    "    result_folder = global_vars['reconstruction_folder_cloud']\n",
    "else:\n",
    "    result_folder = global_vars['reconstruction_folder_local']\n",
    "print(result_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46701d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set location of input files (path from root above)\n",
    "#Note that these were processed such that they already share a coordinate set\n",
    "sst_processed = 'SST/processed/SST_NOAA_OI-V2-1x1_198201-202304.nc'\n",
    "sss_processed = 'SSS/processed/SSS_Met-Office-Hadley-Centre_EN422f-g10-analyses_198201-202304.nc' #previously 202303\n",
    "mld_processed = 'MLD/processed/MLD_IFREMER-deBoyer_DT02-c1m-1x1_198201-202304.nc'\n",
    "chl_processed = 'CHL/processed/CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_198201-202304.nc'\n",
    "pco2_processed = 'pCO2/processed/pCO2_LEAP_SOCAT-ERA5-weighted_198201-202212.nc'\n",
    "xco2_processed = 'xCO2/processed/xCO2_NOAA_xCO2-mm-gl-monthly_198201-202303.nc'\n",
    "list_for_df = [sst_processed, sss_processed, mld_processed, chl_processed, pco2_processed, xco2_processed] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is where we set parameters for the ML algorithm for finding the long term pco2 mean feature\n",
    "\n",
    "#The next variable is for the XGBoost method for both pCO2 Residual and creating the long term pCo2 mean feature. They were determined via a grid search in previous iterations. \n",
    "best_params = {'max_depth': 9, 'n_estimators': 1000} \n",
    "random_seed = 47  #Set the random seeds used for training (should match the number of runs)\n",
    "jobs = -1         #Number of cores you have access to for model training; -1 for all available ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db65bf",
   "metadata": {},
   "source": [
    "# Create Features\n",
    "### Base Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ab49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrfull = xr.merge([xr.open_dataset(data_folder_root+f) for f in list_for_df], compat='broadcast_equals')\n",
    "xrfull.attrs = \"\" #just removing attribute details since wont be accurate anymore\n",
    "#xrfull"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb8d0476",
   "metadata": {},
   "source": [
    "#minor edits to align other versions. To update in data processing\n",
    "#xrfull = xrfull.drop_vars(['clim_repeat','socat_sst','mslp','fco2']) #variables are not needed\n",
    "#xrfull = xrfull.rename({'trend': 'xco2_trend', 'pCO2':'pco2'}) #TBD; to be changed in processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f095ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next add derived (logs)\n",
    "xrfull = xrfull.assign( mld_log = log_or_0_xr(xrfull.mld, 'mld_log') \n",
    "                       ,chl_log = log_or_0_xr(xrfull.chl, 'chl_log')\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#add anomalies fields\n",
    "anomalies = xrfull.groupby(\"time.month\") - xrfull.groupby(\"time.month\").mean(\"time\")\n",
    "anomalies = anomalies.get(['sst','sss','chl_log']) #just need SST, SSS, CHL anomalies\n",
    "anomalies = anomalies.drop('month') \n",
    "anomalies = anomalies.rename({'sst': 'sst_anomaly', 'sss':'sss_anomaly', 'chl_log':'chl_log_anomaly'}) \n",
    "#anomalies\n",
    "xrfull = xrfull.merge(anomalies, compat='identical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add time and space derivations\n",
    "xrfull = xrfull.assign( days_idx = xrfull.time.dt.dayofyear \n",
    "                       ,lon_rad = np.radians(xrfull.xlon)\n",
    "                       ,lat_rad = np.radians(xrfull.ylat)\n",
    "                      )\n",
    "xrfull = xrfull.assign( T0 = np.cos(xrfull.days_idx * 2 * np.pi / 365)\n",
    "                       ,T1 = np.sin(xrfull.days_idx * 2 * np.pi / 365)\n",
    "                       ,A  = np.sin(xrfull.lat_rad)\n",
    "                       ,B  = np.cos(xrfull.lat_rad)*np.sin(xrfull.lon_rad)\n",
    "                       ,C  = -np.cos(xrfull.lat_rad)*np.cos(xrfull.lon_rad)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7040c332",
   "metadata": {},
   "source": [
    "### Set Data Fields/Points For Learning Long Term Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589b0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#This variable is a list of features used for the Long Term pCO2 mean machine learning\n",
    "feature_sel = ['sst','sst_anomaly','sss','sss_anomaly','chl_log','chl_log_anomaly','mld_log','xco2_trend','A','B','C','T0','T1']\n",
    "target_sel = ['fco2']  #previously was pco2\n",
    "\n",
    "xr_for_ocean_co2_mean = xrfull.get(feature_sel + target_sel)  #Note - we train on all available data (no time slice is used here)\n",
    "df_for_ocean_co2_mean = xr_for_ocean_co2_mean.to_dataframe() #expensive function; need lots of RAM \n",
    "df_for_ocean_co2_mean_to_train = df_for_ocean_co2_mean[(~df_for_ocean_co2_mean.isna().any(axis=1))]  #only keep points that are not null \n",
    "print(f'Number of points in time/space for training: {df_for_ocean_co2_mean_to_train.shape[0]}')\n",
    "#df_for_ocean_co2_mean_to_train\n",
    "\n",
    "df_for_ocean_co2_mean_to_predict_temp = df_for_ocean_co2_mean.loc[:,feature_sel]\n",
    "df_for_ocean_co2_mean_to_predict = df_for_ocean_co2_mean_to_predict_temp[(~df_for_ocean_co2_mean_to_predict_temp.isna().any(axis=1))]  #only predict on points with all variables globally\n",
    "print(f'Number of points in time/space available to reconstruct: {df_for_ocean_co2_mean_to_predict.shape[0]}')\n",
    "#df_for_ocean_co2_mean_to_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a41648",
   "metadata": {},
   "source": [
    "### ML for Ocean CO2_Long_Term_Mean Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39899d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = df_for_ocean_co2_mean_to_train.loc[:,feature_sel]\n",
    "y_train = df_for_ocean_co2_mean_to_train.loc[:,target_sel]\n",
    "\n",
    "model = XGBRegressor(random_state=random_seed, **best_params, n_jobs=jobs)\n",
    "print(f'Training started on '+datetime.datetime.now().strftime('%Y-%m-%d %H:%M')+'...')\n",
    "model.fit(X_train, y_train)    #training on all data with no cross validation because we are only calculating a long term average\n",
    "                               #Model evalation for pco2 residual is in the next script\n",
    "ocean_co2_for_mean_recon = model.predict(df_for_ocean_co2_mean_to_predict)\n",
    "print(\"Complete\")  #Training and predicting may take 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514cfad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average across time and add back to dataset \n",
    "ocean_co2_for_mean_recon_xr = pd.DataFrame(ocean_co2_for_mean_recon,index=df_for_ocean_co2_mean_to_predict.index,columns=['ocean_co2_recon_for_mean']).to_xarray()\n",
    "xrfull = xrfull.merge(ocean_co2_for_mean_recon_xr, compat='identical') #add back to full set\n",
    "xrfull = xrfull.assign(ocean_co2_mean = xrfull.ocean_co2_recon_for_mean.mean('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export if desired. Some extra code to find the dates used\n",
    "if True:\n",
    "    min_yearmonth = str(ocean_co2_for_mean_recon_xr.time.min().data.astype('datetime64[s]').item().strftime('%Y%m')) #just gets the min date from the xarray in YYYYMM format\n",
    "    max_yearmonth = str(ocean_co2_for_mean_recon_xr.time.max().data.astype('datetime64[s]').item().strftime('%Y%m')) \n",
    "    ocean_co2_long_term_mean = ocean_co2_for_mean_recon_xr.mean('time')\n",
    "    ocean_co2_long_term_mean = ocean_co2_long_term_mean.rename({'ocean_co2_recon_for_mean': str(target_sel[0])+'_mean'})\n",
    "    ocean_co2_output_name = result_folder+'pCO2_LEAP_XGBoost-'+str(target_sel[0])+'-long-term-mean-from-'+min_yearmonth+'-to-'+max_yearmonth+'.nc'\n",
    "    ocean_co2_long_term_mean.to_netcdf(ocean_co2_output_name)\n",
    "    print(f'Saved: {ocean_co2_output_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf644cc",
   "metadata": {},
   "source": [
    "### Residual (pCO2 T and NonT Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3460369",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8394d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xrfull['ocean_co2_mean']\n",
    "#xrfull.ocean_co2_mean\n",
    "#xrfull[target_sel[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8d393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrfull = xrfull.assign(ocean_co2_T = xrfull['ocean_co2_mean'] * np.exp(0.0423* (xrfull.sst - xrfull.sst.mean(\"time\"))) )\n",
    "xrfull = xrfull.assign(ocean_co2_nonT = xrfull[target_sel[0]] - xrfull.ocean_co2_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform some clean up before exporting\n",
    "\n",
    "#xrfull = xrfull.drop_vars(['ocean_co2_recon_for_mean'])  #optionally could keep/drop this variable\n",
    "xrfull = xrfull.rename({'ocean_co2_T': str(target_sel[0])+'_T'\n",
    "                        ,'ocean_co2_nonT': str(target_sel[0])+'_nonT'\n",
    "                        ,'ocean_co2_mean': str(target_sel[0])+'_mean'\n",
    "                        ,'ocean_co2_recon_for_mean': str(target_sel[0])+'_recon_for_mean'\n",
    "                       })\n",
    "#add attributes as needed here\n",
    "\n",
    "xrfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4533b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export out (may be 2.5GB)\n",
    "output_netcdf_with_date(xrfull, result_folder+'', 'pCO2_LEAP_'+str(target_sel[0])+'-residual-full-dataset-preML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6869328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leap_co2_v1",
   "language": "python",
   "name": "leap_co2_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
